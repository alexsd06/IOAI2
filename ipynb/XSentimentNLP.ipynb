{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843357c5-afd8-47e8-96d6-09e4c29fb61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/alex/Documents/IOAI/Notebooks/venv/lib/python3.10/site-packages (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-5.27.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b40e57-b8c9-4341-94cb-f5380ac9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", device=device,\n",
    "                              model='cardiffnlp/twitter-xlm-roberta-base-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b05edc-5dc1-4d6f-9341-f7f1682e2def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1000 lines!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                I`d have responded, if I were going   neutral\n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                          my boss is bullying me...  negative\n",
       "3                     what interview! leave me alone  negative\n",
       "4   Sons of ****, why couldn`t they put them on t...  negative\n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral\n",
       "6  2am feedings for the baby are fun when he is a...  positive\n",
       "7                                         Soooo high   neutral\n",
       "8                                        Both of you   neutral\n",
       "9   Journey!? Wow... u just became cooler.  hehe....  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('dataset/train.csv', encoding='unicode_escape')\n",
    "df.drop(['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'], axis=1, inplace=True)\n",
    "#mask = df['sentiment'] == 'neutral'\n",
    "#df=df[~mask]\n",
    "#mask= df['text'].str.len() < 100\n",
    "#df=df[~mask]\n",
    "df=df[:1000]\n",
    "print (f'The dataset has {len(df)} lines!')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6e4227-96c9-4f43-8d2e-6b2b04256ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' I`d have responded, if I were going', ' Sooo SAD I will miss you here in San Diego!!!', 'my boss is bullying me...', ' what interview! leave me alone', ' Sons of ****, why couldn`t they put them on the releases we already bought', 'http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth', '2am feedings for the baby are fun when he is all smiles and coos', 'Soooo high', ' Both of you', ' Journey!? Wow... u just became cooler.  hehe... (is that possible!?)']\n"
     ]
    }
   ],
   "source": [
    "text_data=df['text'].to_numpy().astype(str).tolist()\n",
    "sentiment=df['sentiment'].to_numpy().astype(str).tolist()\n",
    "print(text_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8e310d-bd81-4469-b517-36a41cff8557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 s, sys: 2.17 ms, total: 5.61 s\n",
      "Wall time: 5.6 s\n"
     ]
    }
   ],
   "source": [
    "%time output=sentiment_pipeline(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "661eada2-4bfa-4aab-ad35-79ba0041f31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.5402872562408447}, {'label': 'negative', 'score': 0.9343284368515015}, {'label': 'negative', 'score': 0.945700466632843}, {'label': 'negative', 'score': 0.8988997340202332}, {'label': 'negative', 'score': 0.8394114375114441}, {'label': 'negative', 'score': 0.543731689453125}, {'label': 'positive', 'score': 0.8367201089859009}, {'label': 'negative', 'score': 0.4926181435585022}, {'label': 'neutral', 'score': 0.4310312271118164}, {'label': 'positive', 'score': 0.8752656579017639}]\n"
     ]
    }
   ],
   "source": [
    "print(output[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6154969-493e-43d9-825a-95e4ec97ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'neutral', 'positive']\n",
      "Real:      ['neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "predict=[item['label'].lower() for item in output]\n",
    "print ('Predicted:', predict[:10])\n",
    "print ('Real:     ', sentiment[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce15b00-935e-41be-abb9-a2f7a56e1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an accuracy of 69.8%!\n",
      "This model has a loss of 30.2%!\n"
     ]
    }
   ],
   "source": [
    "count_good=0\n",
    "count_bad=0\n",
    "length=len(sentiment)\n",
    "for i in range(0, length):\n",
    "    if predict[i]==sentiment[i]:\n",
    "        count_good+=1\n",
    "    else:\n",
    "        count_bad+=1\n",
    "accuracy=count_good*100/length\n",
    "loss=count_bad*100/length\n",
    "print(f'This model has an accuracy of {accuracy}%!')\n",
    "print(f'This model has a loss of {loss}%!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295a517-36e0-4d60-8f56-29414bb4ff75",
   "metadata": {},
   "source": [
    "**Raport:** \n",
    "1. Accuracy of 83% when classifying between Positive and Negative only.\n",
    "2. Accuracy of 69% when trying to match everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7989b-c3bc-4e19-bf34-66df731885b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
