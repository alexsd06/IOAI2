{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4ba8f6a6-f7a7-4265-a5a5-91284ed47bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89187984-1d18-4a04-a6c0-e9e81367895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check torch minst dataset for how it holds labels\n",
    "dataset_training=torchvision.datasets.MNIST(download=True, root='./data', train=True, transform=torchvision.transforms.ToTensor())\n",
    "loader_training=DataLoader(dataset_training, shuffle=True, batch_size=4)\n",
    "dataset_test=torchvision.datasets.MNIST(download=True, root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "loader_test=DataLoader(dataset_test, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c5d2493-63df-4a5f-8a3b-1282ebfbf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image (file_path):\n",
    "    image=Image.open(file_path)\n",
    "    background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "    background.paste(image, mask=image.split()[3]) # 3 is the alpha channel\n",
    "    background=background.convert('1')\n",
    "    arr=np.array(background)\n",
    "    image.close()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38537fdf-3139-49cf-96e8-7590573ecadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifDataset(Dataset):\n",
    "    def __init__(self, training=None):\n",
    "        self.data=[]\n",
    "        self.label=[]\n",
    "        if os.path.exists(\"data.npy\") and os.path.exists(\"label.npy\"):\n",
    "            self.data=np.load('data.npy')\n",
    "            self.label=np.load('label.npy')\n",
    "        else:\n",
    "            for i in range(0, 10):\n",
    "                cif_path=os.path.join('dataset', str(i), str(i))\n",
    "                files=os.listdir(cif_path)\n",
    "                index=0\n",
    "                for file in files:\n",
    "                    file_path=os.path.join(cif_path, file)\n",
    "                    nd_array=load_image(file_path).flatten()\n",
    "                    self.data.append([nd_array])\n",
    "                    self.label.append(i)\n",
    "                    #if index>1000:\n",
    "                    #    break\n",
    "                    index+=1\n",
    "            self.data=np.float32(np.array(self.data))\n",
    "            self.label=np.long(np.array(self.label))\n",
    "            self.data, self.label=self.unison_shuffled_copies(self.data, self.label)\n",
    "            np.save('data.npy', self.data)\n",
    "            np.save('label.npy', self.label)\n",
    "        cut=int(0.9*len(self.label))\n",
    "        if training==True:\n",
    "            self.data=self.data[:cut]\n",
    "            self.label=self.label[:cut]\n",
    "        elif training==False:\n",
    "            self.data=self.data[cut:]\n",
    "            self.label=self.label[cut:]\n",
    "        \n",
    "    def unison_shuffled_copies(self, a, b):\n",
    "        assert len(a) == len(b)\n",
    "        p = np.random.RandomState(seed=69).permutation(len(a), )\n",
    "        return a[p], b[p]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19129f34-2d26-4106-8866-2ed5cd592250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data=[]\n",
    "        self.label=[]\n",
    "\n",
    "        for file in os.listdir(\"tests\"):\n",
    "            file_path=os.path.join(\"tests\", file)\n",
    "            nd_array=load_image(file_path).flatten()\n",
    "            self.data.append([nd_array])\n",
    "            self.label.append(int(file[0]))\n",
    "            \n",
    "        self.data=np.float32(np.array(self.data))\n",
    "        self.label=np.long(np.array(self.label))\n",
    "        self.data, self.label=self.unison_shuffled_copies(self.data, self.label)\n",
    "\n",
    "    def unison_shuffled_copies(self, a, b):\n",
    "        assert len(a) == len(b)\n",
    "        p = np.random.RandomState(seed=69).permutation(len(a), )\n",
    "        return a[p], b[p]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b7cbe643-621c-4690-945f-e3dd3cd5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training=CifDataset(training=True) #TODO: Implement training and testing data here!\n",
    "loader_training=DataLoader(dataset_training, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb431709-34ea-4808-9d65-2665298db4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test=CifDataset(training=False)\n",
    "#dataset_test=TestDataset()\n",
    "loader_test=DataLoader(dataset_test, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "247b13e1-7ffa-4d69-8f55-a9346ee6dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 96957\n"
     ]
    }
   ],
   "source": [
    "print (f'Training dataset length: {len(dataset_training)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a7140887-2c9c-45c2-8907-2208f7ad6923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset length: 10773\n"
     ]
    }
   ],
   "source": [
    "print (f'Test dataset length: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6f2b43c3-a3af-4342-983c-a788531c3302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "feef4741-9c3b-45e5-8c75-f1b3084199dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifModel(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super().__init__()\n",
    "        self.l1=nn.Linear(28*28, n_hidden)\n",
    "        self.relu=nn.LeakyReLU()\n",
    "        self.l11=nn.Linear(n_hidden, n_hidden)\n",
    "        self.l2=nn.Linear(n_hidden, 10)\n",
    "        self.sgm=nn.Sigmoid()\n",
    "    def forward(self, sample):\n",
    "        sample=self.l1(sample)\n",
    "        sample=self.relu(sample)\n",
    "        sample=self.l11(sample)\n",
    "        sample=self.relu(sample)\n",
    "        sample=self.l2(sample)\n",
    "        #sample=self.sgm(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c848f865-5de7-4231-9590-8f29fc91edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CifModel(100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "55ebc37e-9035-4036-9ef5-24e10233515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=2\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35d62dbe-f90b-4889-ab2c-9f18db0dcefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 0, Loss: 0.000\n",
      "Epoch: 1, Iter: 5000, Loss: 0.013\n",
      "Epoch: 1, Iter: 10000, Loss: 0.051\n",
      "Epoch: 1, Iter: 15000, Loss: 0.008\n",
      "Epoch: 1, Iter: 20000, Loss: 0.000\n",
      "Epoch: 2, Iter: 0, Loss: 0.004\n",
      "Epoch: 2, Iter: 5000, Loss: 0.000\n",
      "Epoch: 2, Iter: 10000, Loss: 0.001\n",
      "Epoch: 2, Iter: 15000, Loss: 0.003\n",
      "Epoch: 2, Iter: 20000, Loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs): #It works on my own dataset as well, but it fails on my samples\n",
    "    index=0\n",
    "    for _, (image, label) in enumerate(loader_training):\n",
    "        image=image.to(device).reshape(-1, 28*28)\n",
    "        label=label.to(device)\n",
    "        y_predict=model(image)\n",
    "        loss=loss_fn(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if index%5000==0:\n",
    "            print (f'Epoch: {epoch+1}, Iter: {index}, Loss: {loss:.3f}')\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "01fbc5a6-c4dc-43f3-8ad2-1183158734f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Accuracy: 99.75247192382812%\n",
      "Accuracy: 99.87561798095703%\n",
      "Accuracy: 99.8338851928711%\n",
      "Accuracy: 99.87531280517578%\n",
      "Accuracy: 99.90019989013672%\n",
      "Accuracy: 99.91680145263672%\n",
      "Accuracy: 99.92867279052734%\n",
      "Accuracy: 99.87515258789062%\n",
      "Accuracy: 99.8890151977539%\n",
      "Accuracy: 99.90010070800781%\n",
      "Accuracy: 99.88646697998047%\n",
      "Accuracy: 99.89591979980469%\n",
      "Accuracy: 99.90391540527344%\n",
      "Accuracy: 99.89292907714844%\n",
      "Accuracy: 99.88341522216797%\n",
      "Accuracy: 99.89070129394531%\n",
      "Accuracy: 99.8971176147461%\n",
      "Accuracy: 99.87506866455078%\n",
      "Accuracy: 99.88164520263672%\n",
      "Accuracy: 99.87506866455078%\n",
      "Accuracy: 99.86911010742188%\n",
      "Accuracy: 99.86370086669922%\n",
      "Accuracy: 99.85875701904297%\n",
      "Accuracy: 99.8542251586914%\n",
      "Accuracy: 99.85005950927734%\n",
      "Accuracy: 99.8462142944336%\n",
      "Final Accuracy: 99.8462142944336%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    index=0\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    for _, (image, label) in enumerate(loader_test):\n",
    "        image=image.to(device).reshape(-1, 28*28)\n",
    "        label=label.to(device)\n",
    "        y_pred=model(image)\n",
    "        _, nr=y_pred.detach().max(dim=1)\n",
    "        num_correct += (nr == label).sum()\n",
    "        num_samples += nr.size(0)\n",
    "        if (index%100==0):\n",
    "            acc=100*num_correct/num_samples\n",
    "            print (f'Accuracy: {acc}%')\n",
    "        index+=1\n",
    "    print (f'Final Accuracy: {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2b408025-d967-4551-a8cb-ef24cf3453e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model.ckpt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b839d200-202b-4264-a326-37380400936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': n_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf8f3f-3905-4ddf-8576-b651434e5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Accuracy: 97.40733337402344% (5 Epoch)\n",
    "# Final Accuracy: 97.56351470947266% (2 Epoch)\n",
    "# Final Accuracy: 96.02249145507812% (2 Epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
