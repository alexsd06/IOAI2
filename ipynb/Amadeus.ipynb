{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d19fd6e5-1ee3-4296-9bcb-0b68bc907130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments, pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61d8ef98-90c9-4e84-814c-cb2ee81db4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['completion', 'history', 'scenario', 'speaker'],\n",
      "        num_rows: 7831\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset=load_dataset('Heralax/Augmental-Dataset')\n",
    "print (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c5470d4-3682-4108-ac68-9378177fc318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you come with me for a moment? Huh? Stop fooling around and come with me. What are you talking\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.filter(lambda x: False if x['speaker']!='Kurisu' else True)\n",
    "train_dataset=dataset['train']\n",
    "kurisu_replicas=train_dataset['completion']\n",
    "def use_regex(input_text):\n",
    "    out=re.findall(r'\"(.*?)\"', input_text)\n",
    "    if not out:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return out[0]\n",
    "kurisu_replicas=[use_regex(inp) for inp in kurisu_replicas]\n",
    "kurisu_replicas=[x for x in kurisu_replicas if x]\n",
    "data=\"\"\n",
    "for item in kurisu_replicas:\n",
    "    data=data+item+' '#+'<|endoftext|>'\n",
    "print(data[:100])\n",
    "with open('kurisu.txt', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4461dd15-2254-43ac-abc2-7f75b2fc25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator\n",
    "\n",
    "\n",
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  token_ids = train_dataset.examples\n",
    "  decoded_text = tokenizer.decode(token_ids[0])\n",
    "  print(decoded_text)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a23506ca-2a12-4fd5-82e7-6436bc839656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"kurisu.txt\"\n",
    "model_name = 'gpt2'\n",
    "output_dir = 'gpt2-kurisu'\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 40.0\n",
    "save_steps = 500 #Lower this next training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b733372-62ac-42f8-94a1-0c83e8716646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/IOAI/Notebooks/venv/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you come with me for a moment? Huh? Stop fooling around and come with me. What are you talking about? I just need to ask you something. What's with this 'Organization' stuff?...So you talk to yourself. What were you trying to tell me earlier? About fifteen minutes ago. Before the conference started. You were trying to tell me something, right? You looked really upset. You looked like you were going to start crying any second. Why? Have we met before? And how do you know my name? Huh? I'm sorry! Is there something wrong? Hey, that hurts!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1040/1040 06:44, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.079500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It takes about 30 minutes to train in colab.\n",
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "813d7abd-5a47-4bcd-9050-bc84739dc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model='gpt2-kurisu', device='cuda')\n",
    "generator2 = pipeline('text-generation', model='gpt2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d889292e-b3d4-4c10-85da-63a40233b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Time Leap Machine. C-come on! Time travel to the past is possible right now. It wouldn't have been possible five hours ago. It's so unbelievably dangerous! How could you plan to sneak in a time machine!? It's dangerous to even think about it, Okabe. This is Russia. Taking a break at night is practically forbidden here. Actually, I'm not even sure what to say. Not a chance. This isn't about me. Here, I want to expose the lies of the capitalist system, and expose the failures of the past five years. Shut up, perv. Remember that I said I'm not a hypocrite? You win here by being strong, Okabe. If you want your revenge, I'm almost certain you will. But I'm asking for your loyalty, okay? You're such a wimp, you know? Don't take everything I say seriously. Remember that I said I'm not a hypocrite? You\n",
      "----------------------------------------------\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "\n",
      "As well\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "D\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "D\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "D\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "D\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "D\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "I\n",
      "\n",
      "F\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n",
      "F\n",
      "\n",
      "V\n",
      "\n",
      "B\n",
      "\n",
      "A\n",
      "\n",
      "Meter\n",
      "\n",
      "As well\n",
      "\n",
      "I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "message=\"\"\"\n",
    "The\n",
    "\"\"\"\n",
    "max_len=200\n",
    "num_seq=3\n",
    "#set_seed(42)\n",
    "print(generator(message, max_length=max_len, num_return_sequences=num_seq)[0]['generated_text'].replace(message, ''))\n",
    "print ('----------------------------------------------')\n",
    "print(generator2(message, max_length=max_len, num_return_sequences=num_seq)[0]['generated_text'].replace(message, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad9bdf-19c7-4d8a-8dc9-867dacb2ac05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897cee6-8f5f-4c42-bbbe-85710fcbf80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8939a6-78f7-44e4-910a-ba85b5331217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75738317-1bdb-4e78-a1e4-4ccf0d152944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebf460-cc77-4b72-b1b2-d7b62c61dee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
